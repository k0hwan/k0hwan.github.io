<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Kyunghwan Kim | 김경환</title> <meta name="author" content="Kyunghwan Kim"> <meta name="description" content="HCI Researcher. Master's student at Human-Computer Interaction Lab (HCIL), School of Computing, KAIST. I connect Humans with Computers through novel Physical Interaction techniques!! "> <meta name="keywords" content="kyunghwan-kim, kaist, hci, hcil, homepage, chi, uist, masters-student, physical-interaction, interaction-techniques, extended-reality, xr"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8D%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://k0hwan.github.io/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?3dd82e91913a2c1265c0f80e41ff39e2"></script> <script src="/assets/js/dark_mode.js?6458e63976eae16c0cbe86b97023895a"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Kyunghwan Kim | 김경환</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/patents/">Patents</a> </li> <li class="nav-item "> <a class="nav-link" target="_blank" href="https://k0hwan.github.io/assets/pdf/CV_KyunghwanKim.pdf">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"> <abbr class="badge" style="background-color:#1d3752; margin-bottom: 2mm;">Virtual Reality</abbr><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/rdw2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/rdw2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/rdw2-1400.webp"></source> <img src="/assets/img/publication_preview/rdw2.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="rdw2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1007/s10055-024-00997-y" class="col-sm-8"> <div class="title">Evaluation of visual, auditory, and olfactory stimulus-based attractors for intermittent reorientation in virtual reality locomotion</div> <div class="author"> Jieun Lee, Seokhyun Hwang, <strong><span style="color:var(--global-theme-color)">Kyunghwan Kim</span></strong>, and SeungJun Kim</div> <div class="periodical"> <em>Springer Virtual Reality ’24</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a> <a href="https://link.springer.com/10.1007/s10055-024-00997-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>In virtual reality, redirected walking (RDW) enables users to stay within the tracking area while feeling that they are traveling in a virtual space that is larger than the physical space. RDW uses a visual attractor to the user’s sight and scene manipulation for intermittent reorientation. However, repeated usage can hinder the virtual world immersion and weaken the reorientation performance. In this study, we propose using sounds and smells as alternative stimuli to draw the user’s attention implicitly and sustain the attractor’s performance for intermittent reorientation. To achieve this, we integrated visual, auditory, and olfactory attractors into an all-in-one stimulation system. Experiments revealed that the auditory attractor caused the fastest reorientation, the olfactory attractor induced the widest angular difference, and the attractor with the combined auditory and olfactory stimuli induced the largest angular speed, keeping users from noticing the manipulation. The findings demonstrate the potential of nonvisual attractors to reorient users in situations requiring intermittent reorientation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"> <abbr class="badge" style="background-color:#7030A0; margin-bottom: 2mm;">CHI Interactivity</abbr><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/stbutton-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/stbutton-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/stbutton-1400.webp"></source> <img src="/assets/img/publication_preview/stbutton.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="stbutton.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/3613905.3648671" class="col-sm-8"> <div class="title">STButton: Exploring Opportunities for Buttons with Spatio-Temporal Tactile Output</div> <div class="author"> Yeonsu Kim, Jisu Yim, Jaehyun Kim, <strong><span style="color:var(--global-theme-color)">Kyunghwan Kim</span></strong>, and Geehyuk Lee</div> <div class="periodical"> <em>CHI ’24 Interactivity (Extended Abstracts)</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a> <a href="https://doi.org/10.1145/3613905.3648671" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://dl.acm.org/doi/fullHtml/10.1145/3613905.3648671" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/stbutton_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>We present STButton, a physical button with a high-resolution spatio-temporal tactile feedback surface. The 5 x 8 pin array tactile display size of 20mm x 28mm enables buttons to express various types of information, such as value with the number of raised pins, direction with the location of raised pins, and duration of time with blinking animation. With a highly expressive tactile surface, the button can seamlessly transfer assistive feedforward and feedback during spontaneous button interaction, such as touching to locate the button or applying gradual pressure to press the button. In the demonstration, attendees experience five scenarios of button interaction: the seat heater button on a car, the volume control button on a remote controller, the power button on a laptop, the menu button on a VR controller, and the play button on a game controller. In each scenario, the representative role of tactile feedback is configured differently, allowing attendees to experience the rich interaction space and potential benefits of STButton. Early accessed attendees appreciated the unique opportunity to transfer information with a highly expressive tactile surface and emphasized that STButton adds a tangible layer to the user experience, enhancing emotional and sensory engagement.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"> <abbr class="badge" style="background-color:#0E8288; margin-bottom: 2mm;">UIST Demo</abbr><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/vrt-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/vrt-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/vrt-1400.webp"></source> <img src="/assets/img/publication_preview/vrt.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="vrt.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/3586182.3615813" class="col-sm-8"> <div class="title">Virtual Rolling Temple: Expanding the Vertical Input Space of a Smart Glasses Touchpad</div> <div class="author"> <strong><span style="color:var(--global-theme-color)">Kyunghwan Kim</span></strong>, and Geehyuk Lee</div> <div class="periodical"> <em>UIST ’23 Demo (Adjunct)</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a> <a href="https://doi.org/10.1145/3586182.3615813" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://dl.acm.org/doi/fullHtml/10.1145/3586182.3615813" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/vrt_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Smart glasses have not favored two-dimensional (2D) GUI. Such a trend may have originated from the limitations of smart glasses in display and input devices. While the display restriction is rapidly being resolved nowadays, 1D GUI is still the majority, indicating that the touch input device is the possible bottleneck. To tackle this issue by expanding the vertical input space of the temple touchpad, we propose the Virtual Rolling Temple (VRT). The concept is to perform 2D gestures by moving the hand in any direction while keep touching the prototype as if the temple rotates. The VRT touchpad is as thin as the spectacles’ temples, but it provides the users with input space approximately equivalent to an 80×80 mm square touchpad. This is 8 and 13.9 times larger than Google Glass and VUZIX M400, respectively. To validate the concept of the VRT, we constructed three demo scenarios: 2D Pointing, 2D Menu, and 2D Gesture, to cover different types of general 2D input for smart glasses.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"> <abbr class="badge" style="background-color:#000000; margin-bottom: 2mm;">B.S. Thesis</abbr><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/bsthesis-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/bsthesis-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/bsthesis-1400.webp"></source> <img src="/assets/img/publication_preview/bsthesis.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="bsthesis.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kyunghwan_bs" class="col-sm-8"> <div class="title">Analysis of the Effect of Vection Generated by Directional Optical Flow in the VR Redirected Walking Scenario (VR 방향 전환 보행 시나리오에서 방향성을 가지는 Optical Flow에 의해 생성되는 Vection의 영향 분석)</div> <div class="author"> <strong><span style="color:var(--global-theme-color)">Kyunghwan Kim</span></strong> </div> <div class="periodical"> <em>GIST College EECS - Thesis for Bachelor’s Degree</em> </div> <div class="periodical"> </div> <div class="links"> <div> <b>Advisor</b>: Jeany Son, <b>Co-Advisor</b>: SeungJun Kim</div> <div>🏆 <b>Best B.S. Thesis Poster Presentation Award (1st place)</b> </div> <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a> <a href="/assets/pdf/bsthesis_poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Human instinct is eager to explore the unexplored. The concept of Redirected Walking (RDW) was introduced to help with the aspiration of endeavoring to travel to a larger virtual environment by walking. However, compared to general walking scenarios in the real world, wearing Virtual Reality (VR) headsets negatively impacts gait stability. Adding RDW techniques to this would increase the mismatch between visual and vestibular information, resulting in even lower gait stability and possible motion sickness. This study aims to discover if vection generated by Optical Flow (OF) can help improve gait stability, enlarge Detection Threshold (DT) and relieve motion sickness. The results showed that adding vection to the RDW scenario hinders M/L gait stability while there was not much impact on A/P gait stability. Vection also slightly increased simulator sickness and decreased presence in a few combinations, and its relationship with DT was found to require a new measurement method.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2"> <abbr class="badge" style="background-color:#7030A0; margin-bottom: 2mm;">CHI LBW</abbr><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/rdw-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/rdw-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/rdw-1400.webp"></source> <img src="/assets/img/publication_preview/rdw.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="rdw.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1145/3491101.3519719" class="col-sm-8"> <div class="title">Auditory and Olfactory Stimuli-Based Attractors to Induce Reorientation in Virtual Reality Forward Redirected Walking</div> <div class="author"> Jieun Lee, Seokhyun Hwang, <strong><span style="color:var(--global-theme-color)">Kyunghwan Kim</span></strong>, and SeungJun Kim</div> <div class="periodical"> <em>CHI ’22 LBW (Extended Abstracts)</em> </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">ABSTRACT</a> <a href="https://doi.org/10.1145/3491101.3519719" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://dl.acm.org/doi/fullHtml/10.1145/3491101.3519719" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Redirected walking (RDW) visually manipulates the virtual environment to imperceptibly redirect the walkers to keep them in the tracking area, and offers a larger space than physical space. An attractor is a redirected walking technique that captures the walker’s attention and manipulates the walker’s trajectory through rotational gain. However, the attractor visually manipulates the walker’s virtual environment using a predefined rotational gain, and having to constantly gaze at the attractor or the attractor frequently appearing until the walker’s direction matches the desired direction, are problems limiting the application of visual attractors. Moreover, when the walker is unable to recognize or ignores the attractor, reorientation fails. In this study, we designed a human-sense-stimulating attractor that utilizes the auditory and olfactory senses to improve the rotational gain, naturalness, and immersion and decrease the chance of reorientation failure. Although sound and scents are invisible, they can be detected through direction; however, humans cannot recognize the accurate direction of a sound or scent. Based on these characteristics, auditory and olfactory attractors are proposed. We measured the amount of reorientation induced by the auditory and olfactory attractors and calculated the reorientation success rate. Additionally, the naturalness and immersion of the attractor were evaluated. The auditory attractor has a high reorientation success rate, naturalness, and immersion. The olfactory attractor induces more turn changes in the walker than other attractors, and a high number of turn changes leads to a larger rotational gain. Auditory and olfactory-based attractors have the potential to overcome the shortcomings of visual attractors such as the frequent interventions.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Kyunghwan Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>. Last updated: May 14, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>